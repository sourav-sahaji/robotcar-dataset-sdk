{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Rectify and Save Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# Copyright (c) 2017 University of Oxford\n",
    "# Authors:\n",
    "#  Geoff Pascoe (gmp@robots.ox.ac.uk)\n",
    "#\n",
    "# This work is licensed under the Creative Commons\n",
    "# Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
    "# To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc-sa/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "\n",
    "class CameraModel:\n",
    "    \"\"\"Provides intrinsic parameters and undistortion LUT for a camera.\n",
    "\n",
    "    Attributes:\n",
    "        camera (str): Name of the camera.\n",
    "        camera sensor (str): Name of the sensor on the camera for multi-sensor cameras.\n",
    "        focal_length (tuple[float]): Focal length of the camera in horizontal and vertical axis, in pixels.\n",
    "        principal_point (tuple[float]): Principal point of camera for pinhole projection model, in pixels.\n",
    "        G_camera_image (:obj: `numpy.matrixlib.defmatrix.matrix`): Transform from image frame to camera frame.\n",
    "        bilinear_lut (:obj: `numpy.ndarray`): Look-up table for undistortion of images, mapping pixels in an undistorted\n",
    "            image to pixels in the distorted image\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models_dir, images_dir):\n",
    "        \"\"\"Loads a camera model from disk.\n",
    "\n",
    "        Args:\n",
    "            models_dir (str): directory containing camera model files.\n",
    "            images_dir (str): directory containing images for which to read camera model.\n",
    "\n",
    "        \"\"\"\n",
    "        self.camera = None\n",
    "        self.camera_sensor = None\n",
    "        self.focal_length = None\n",
    "        self.principal_point = None\n",
    "        self.G_camera_image = None\n",
    "        self.bilinear_lut = None\n",
    "\n",
    "        self.__load_intrinsics(models_dir, images_dir)\n",
    "        self.__load_lut(models_dir, images_dir)\n",
    "\n",
    "    def project(self, xyz, image_size):\n",
    "        \"\"\"Projects a pointcloud into the camera using a pinhole camera model.\n",
    "\n",
    "        Args:\n",
    "            xyz (:obj: `numpy.ndarray`): 3xn array, where each column is (x, y, z) point relative to camera frame.\n",
    "            image_size (tuple[int]): dimensions of image in pixels\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: 2xm array of points, where each column is the (u, v) pixel coordinates of a point in pixels.\n",
    "            numpy.array: array of depth values for points in image.\n",
    "\n",
    "        Note:\n",
    "            Number of output points m will be less than or equal to number of input points n, as points that do not\n",
    "            project into the image are discarded.\n",
    "\n",
    "        \"\"\"\n",
    "        if xyz.shape[0] == 3:\n",
    "            xyz = np.stack((xyz, np.ones((1, xyz.shape[1]))))\n",
    "        xyzw = np.linalg.solve(self.G_camera_image, xyz)\n",
    "\n",
    "        # Find which points lie in front of the camera\n",
    "        in_front = [i for i in range(0, xyzw.shape[1]) if xyzw[2, i] >= 0]\n",
    "        xyzw = xyzw[:, in_front]\n",
    "\n",
    "        uv = np.vstack((self.focal_length[0] * xyzw[0, :] / xyzw[2, :] + self.principal_point[0],\n",
    "                        self.focal_length[1] * xyzw[1, :] / xyzw[2, :] + self.principal_point[1]))\n",
    "\n",
    "        in_img = [i for i in range(0, uv.shape[1])\n",
    "                  if 0.5 <= uv[0, i] <= image_size[1] and 0.5 <= uv[1, i] <= image_size[0]]\n",
    "\n",
    "        return uv[:, in_img], np.ravel(xyzw[2, in_img])\n",
    "\n",
    "    def undistort(self, image):\n",
    "        \"\"\"Undistorts an image.\n",
    "\n",
    "        Args:\n",
    "            image (:obj: `numpy.ndarray`): A distorted image. Must be demosaiced - ie. must be a 3-channel RGB image.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Undistorted version of image.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if image size does not match camera model.\n",
    "            ValueError: if image only has a single channel.\n",
    "\n",
    "        \"\"\"\n",
    "        if image.shape[0] * image.shape[1] != self.bilinear_lut.shape[0]:\n",
    "            raise ValueError('Incorrect image size for camera model')\n",
    "\n",
    "        lut = self.bilinear_lut[:, 1::-1].T.reshape((2, image.shape[0], image.shape[1]))\n",
    "\n",
    "        if len(image.shape) == 1:\n",
    "            raise ValueError('Undistortion function only works with multi-channel images')\n",
    "\n",
    "        undistorted = np.rollaxis(np.array([map_coordinates(image[:, :, channel], lut, order=1)\n",
    "                                for channel in range(0, image.shape[2])]), 0, 3)\n",
    "\n",
    "        return undistorted.astype(image.dtype)\n",
    "\n",
    "    def __get_model_name(self, images_dir):\n",
    "        self.camera = re.search('(stereo|mono_(left|right|rear))', images_dir).group(0)\n",
    "        if self.camera == 'stereo':\n",
    "            self.camera_sensor = re.search('(left|centre|right)', images_dir).group(0)\n",
    "            if self.camera_sensor == 'left':\n",
    "                return 'stereo_wide_left'\n",
    "            elif self.camera_sensor == 'right':\n",
    "                return 'stereo_wide_right'\n",
    "            elif self.camera_sensor == 'centre':\n",
    "                return 'stereo_narrow_left'\n",
    "            else:\n",
    "                raise RuntimeError('Unknown camera model for given directory: ' + images_dir)\n",
    "        else:\n",
    "            return self.camera\n",
    "\n",
    "    def __load_intrinsics(self, models_dir, images_dir):\n",
    "        model_name = self.__get_model_name(images_dir)\n",
    "        intrinsics_path = os.path.join(models_dir, model_name + '.txt')\n",
    "\n",
    "        with open(intrinsics_path) as intrinsics_file:\n",
    "            vals = [float(x) for x in next(intrinsics_file).split()]\n",
    "            self.focal_length = (vals[0], vals[1])\n",
    "            self.principal_point = (vals[2], vals[3])\n",
    "\n",
    "            G_camera_image = []\n",
    "            for line in intrinsics_file:\n",
    "                G_camera_image.append([float(x) for x in line.split()])\n",
    "            self.G_camera_image = np.array(G_camera_image)\n",
    "\n",
    "    def __load_lut(self, models_dir, images_dir):\n",
    "        model_name = self.__get_model_name(images_dir)\n",
    "        lut_path = os.path.join(models_dir, model_name + '_distortion_lut.bin')\n",
    "\n",
    "        lut = np.fromfile(lut_path, np.double)\n",
    "        lut = lut.reshape([2, lut.size // 2])\n",
    "        self.bilinear_lut = lut.transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# Copyright (c) 2017 University of Oxford\n",
    "# Authors:\n",
    "#  Geoff Pascoe (gmp@robots.ox.ac.uk)\n",
    "#\n",
    "# This work is licensed under the Creative Commons\n",
    "# Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
    "# To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc-sa/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "#\n",
    "###############################################################################\n",
    "\n",
    "import re\n",
    "from PIL import Image\n",
    "from colour_demosaicing import demosaicing_CFA_Bayer_bilinear as demosaic\n",
    "\n",
    "BAYER_STEREO = 'gbrg'\n",
    "BAYER_MONO = 'rggb'\n",
    "\n",
    "\n",
    "def load_image(image_path, model=None):\n",
    "    \"\"\"Loads and rectifies an image from file.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): path to an image from the dataset.\n",
    "        model (camera_model.CameraModel): if supplied, model will be used to undistort image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: demosaiced and optionally undistorted image\n",
    "\n",
    "    \"\"\"\n",
    "    if model:\n",
    "        camera = model.camera\n",
    "    else:\n",
    "        camera = re.search('(stereo|mono_(left|right|rear))', image_path).group(0)\n",
    "    if camera == 'stereo':\n",
    "        pattern = BAYER_STEREO\n",
    "    else:\n",
    "        pattern = BAYER_MONO\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    img = demosaic(img, pattern)\n",
    "    if model:\n",
    "        img = model.undistort(img)\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demosaic and Undistort all images and create a video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgFolderPath = \"/workspace/dataset2/current/data/oxford/2014-12-10-18-10-50/stereo/\"\n",
    "imgNamesFile = imgFolderPath+\"left.txt\"\n",
    "imgOutPath = \"/workspace/dataset2/current/data/oxford/2014-12-10-18-10-50/stereo/left_rect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgNames = np.loadtxt(imgNamesFile,dtype='str')\n",
    "numImages = imgNames.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleImagePath = imgFolderPath+\"left/\"+imgNames[0]\n",
    "sampleImg = cv2.imread(sampleImagePath)\n",
    "plt.imshow(sampleImg)\n",
    "plt.show()\n",
    "\n",
    "camModel = CameraModel(models_dir=\"../models/\",images_dir=sampleImagePath)\n",
    "img = load_image(sampleImagePath,camModel)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img.shape,sampleImg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imgArray = []\n",
    "for i in range(numImages):\n",
    "    img1 = load_image(imgFolderPath+\"left/\"+imgNames[i],camModel)\n",
    "    img2 = cv2.cvtColor(img1,cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(imgOutPath+str(i).zfill(7)+\".png\",img2)\n",
    "#     img2 = cv2.resize(img1,(640,480),cv2.INTER_AREA)\n",
    "#     imgArray.append(img2)\n",
    "    \n",
    "    if(i%100==0):\n",
    "        print(i+1,\" Images Read\")\n",
    "#     plt.imshow(img2)\n",
    "#     plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv2.VideoWriter(\"writer1.mpeg\",cv2.VideoWriter_fourcc(*'MPEG'),30,(640,480),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seq2Write = imgSeqRaw2[uniIndicesClubbed2,...]\n",
    "# numImages = seq2Write.shape[0]\n",
    "# print(\"Num images - \",numImages)\n",
    "\n",
    "# cap2 = cv2.VideoWriter(folderPath+\"test2.mpeg\",cv2.VideoWriter_fourcc(*'MPEG'),30,(64,32),False)\n",
    "# imgCounter = 0\n",
    "# # lastImg = 0\n",
    "# for i in range(numImages):\n",
    "#     img = seq2Write[i,...]+127\n",
    "#     img = (img).astype('uint8')\n",
    "# #     img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "#     cap2.write(img)\n",
    "#     imgCounter += 1\n",
    "    \n",
    "# cap = cv2.VideoCapture(folderPath+\"test2.mpeg\")\n",
    "# numImages = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# print(\"Num images - \",numImages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
