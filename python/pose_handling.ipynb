{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copied from transform.py and interpolate_poses.py resp... \n",
    "docker run -it --net=host -p 127.0.0.1:8889:8888 -v /home/sourav/workspace/:/workspace/ -v /media/sourav/Default2/Users/n9349995/Desktop/dataset/:/workspace/dataset/ -v /media/sourav/My\\ Passport1/:/workspace/dataset2 souravgarg/opuc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# Copyright (c) 2017 University of Oxford\n",
    "# Authors:\n",
    "#  Geoff Pascoe (gmp@robots.ox.ac.uk)\n",
    "#\n",
    "# This work is licensed under the Creative Commons\n",
    "# Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
    "# To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc-sa/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib as matlib\n",
    "from math import sin, cos, atan2, sqrt\n",
    "\n",
    "MATRIX_MATCH_TOLERANCE = 1e-4\n",
    "\n",
    "\n",
    "def build_se3_transform(xyzrpy):\n",
    "    \"\"\"Creates an SE3 transform from translation and Euler angles.\n",
    "\n",
    "    Args:\n",
    "        xyzrpy (list[float]): translation and Euler angles for transform. Must have six components.\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrixlib.defmatrix.matrix: SE3 homogeneous transformation matrix\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if `len(xyzrpy) != 6`\n",
    "\n",
    "    \"\"\"\n",
    "    if len(xyzrpy) != 6:\n",
    "        raise ValueError(\"Must supply 6 values to build transform\")\n",
    "\n",
    "    se3 = matlib.identity(4)\n",
    "    se3[0:3, 0:3] = euler_to_so3(xyzrpy[3:6])\n",
    "    se3[0:3, 3] = np.matrix(xyzrpy[0:3]).transpose()\n",
    "    return se3\n",
    "\n",
    "\n",
    "def euler_to_so3(rpy):\n",
    "    \"\"\"Converts Euler angles to an SO3 rotation matrix.\n",
    "\n",
    "    Args:\n",
    "        rpy (list[float]): Euler angles (in radians). Must have three components.\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrixlib.defmatrix.matrix: 3x3 SO3 rotation matrix\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if `len(rpy) != 3`.\n",
    "\n",
    "    \"\"\"\n",
    "    if len(rpy) != 3:\n",
    "        raise ValueError(\"Euler angles must have three components\")\n",
    "\n",
    "    R_x = np.matrix([[1, 0, 0],\n",
    "                     [0, cos(rpy[0]), -sin(rpy[0])],\n",
    "                     [0, sin(rpy[0]), cos(rpy[0])]])\n",
    "    R_y = np.matrix([[cos(rpy[1]), 0, sin(rpy[1])],\n",
    "                     [0, 1, 0],\n",
    "                     [-sin(rpy[1]), 0, cos(rpy[1])]])\n",
    "    R_z = np.matrix([[cos(rpy[2]), -sin(rpy[2]), 0],\n",
    "                     [sin(rpy[2]), cos(rpy[2]), 0],\n",
    "                     [0, 0, 1]])\n",
    "    R_zyx = R_z * R_y * R_x\n",
    "    return R_zyx\n",
    "\n",
    "\n",
    "def so3_to_euler(so3):\n",
    "    \"\"\"Converts an SO3 rotation matrix to Euler angles\n",
    "\n",
    "    Args:\n",
    "        so3: 3x3 rotation matrix\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrixlib.defmatrix.matrix: list of Euler angles (size 3)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if so3 is not 3x3\n",
    "        ValueError: if a valid Euler parametrisation cannot be found\n",
    "\n",
    "    \"\"\"\n",
    "    if so3.shape != (3, 3):\n",
    "        raise ValueError(\"SO3 matrix must be 3x3\")\n",
    "    roll = atan2(so3[2, 1], so3[2, 2])\n",
    "    yaw = atan2(so3[1, 0], so3[0, 0])\n",
    "    denom = sqrt(so3[0, 0] ** 2 + so3[1, 0] ** 2)\n",
    "    pitch_poss = [atan2(-so3[2, 0], denom), atan2(-so3[2, 0], -denom)]\n",
    "\n",
    "    R = euler_to_so3((roll, pitch_poss[0], yaw))\n",
    "\n",
    "    if (so3 - R).sum() < MATRIX_MATCH_TOLERANCE:\n",
    "        return np.matrix([roll, pitch_poss[0], yaw])\n",
    "    else:\n",
    "        R = euler_to_so3((roll, pitch_poss[1], yaw))\n",
    "        if (so3 - R).sum() > MATRIX_MATCH_TOLERANCE:\n",
    "            raise ValueError(\"Could not find valid pitch angle\")\n",
    "        return np.matrix([roll, pitch_poss[1], yaw])\n",
    "\n",
    "\n",
    "def so3_to_quaternion(so3):\n",
    "    \"\"\"Converts an SO3 rotation matrix to a quaternion\n",
    "\n",
    "    Args:\n",
    "        so3: 3x3 rotation matrix\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: quaternion [w, x, y, z]\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if so3 is not 3x3\n",
    "    \"\"\"\n",
    "    if so3.shape != (3, 3):\n",
    "        raise ValueError(\"SO3 matrix must be 3x3\")\n",
    "\n",
    "    R_xx = so3[0, 0]\n",
    "    R_xy = so3[0, 1]\n",
    "    R_xz = so3[0, 2]\n",
    "    R_yx = so3[1, 0]\n",
    "    R_yy = so3[1, 1]\n",
    "    R_yz = so3[1, 2]\n",
    "    R_zx = so3[2, 0]\n",
    "    R_zy = so3[2, 1]\n",
    "    R_zz = so3[2, 2]\n",
    "\n",
    "    try:\n",
    "        w = sqrt(so3.trace() + 1) / 2\n",
    "    except(ValueError):\n",
    "        # w is non-real\n",
    "        w = 0\n",
    "\n",
    "    x = sqrt(1 + R_xx - R_yy - R_zz) / 2\n",
    "    y = sqrt(1 + R_yy - R_xx - R_zz) / 2\n",
    "    z = sqrt(1 + R_zz - R_yy - R_xx) / 2\n",
    "\n",
    "    max_index = max(range(4), key=[w, x, y, z].__getitem__)\n",
    "\n",
    "    if max_index == 0:\n",
    "        x = (R_zy - R_yz) / (4 * w)\n",
    "        y = (R_xz - R_zx) / (4 * w)\n",
    "        z = (R_yx - R_xy) / (4 * w)\n",
    "    elif max_index == 1:\n",
    "        w = (R_zy - R_yz) / (4 * x)\n",
    "        y = (R_xy + R_yx) / (4 * x)\n",
    "        z = (R_zx + R_xz) / (4 * x)\n",
    "    elif max_index == 2:\n",
    "        w = (R_xz - R_zx) / (4 * y)\n",
    "        x = (R_xy + R_yx) / (4 * y)\n",
    "        z = (R_yz + R_zy) / (4 * y)\n",
    "    elif max_index == 3:\n",
    "        w = (R_yx - R_xy) / (4 * z)\n",
    "        x = (R_zx + R_xz) / (4 * z)\n",
    "        y = (R_yz + R_zy) / (4 * z)\n",
    "\n",
    "    return np.array([w, x, y, z])\n",
    "\n",
    "\n",
    "def se3_to_components(se3):\n",
    "    \"\"\"Converts an SE3 rotation matrix to linear translation and Euler angles\n",
    "\n",
    "    Args:\n",
    "        se3: 4x4 transformation matrix\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrixlib.defmatrix.matrix: list of [x, y, z, roll, pitch, yaw]\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if se3 is not 4x4\n",
    "        ValueError: if a valid Euler parametrisation cannot be found\n",
    "\n",
    "    \"\"\"\n",
    "    if se3.shape != (4, 4):\n",
    "        raise ValueError(\"SE3 transform must be a 4x4 matrix\")\n",
    "    xyzrpy = np.empty(6)\n",
    "    xyzrpy[0:3] = se3[0:3, 3].transpose()\n",
    "    xyzrpy[3:6] = so3_to_euler(se3[0:3, 0:3])\n",
    "    return xyzrpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# Copyright (c) 2017 University of Oxford\n",
    "# Authors:\n",
    "#  Geoff Pascoe (gmp@robots.ox.ac.uk)\n",
    "#\n",
    "# This work is licensed under the Creative Commons\n",
    "# Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
    "# To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc-sa/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "import bisect\n",
    "import csv\n",
    "import numpy as np\n",
    "import numpy.matlib as ml\n",
    "from transform import *\n",
    "\n",
    "\n",
    "def interpolate_vo_poses(vo_path, pose_timestamps, origin_timestamp):\n",
    "    \"\"\"Interpolate poses from visual odometry.\n",
    "\n",
    "    Args:\n",
    "        vo_path (str): path to file containing relative poses from visual odometry.\n",
    "        pose_timestamps (list[int]): UNIX timestamps at which interpolated poses are required.\n",
    "        origin_timestamp (int): UNIX timestamp of origin frame. Poses will be reported relative to this frame.\n",
    "\n",
    "    Returns:\n",
    "        list[numpy.matrixlib.defmatrix.matrix]: SE3 matrix representing interpolated pose for each requested timestamp.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(vo_path) as vo_file:\n",
    "        vo_reader = csv.reader(vo_file)\n",
    "        headers = next(vo_file)\n",
    "\n",
    "        vo_timestamps = [0]\n",
    "        abs_poses = [ml.identity(4)]\n",
    "\n",
    "        lower_timestamp = min(min(pose_timestamps), origin_timestamp)\n",
    "        upper_timestamp = max(max(pose_timestamps), origin_timestamp)\n",
    "\n",
    "        for row in vo_reader:\n",
    "            timestamp = int(row[0])\n",
    "            if timestamp < lower_timestamp:\n",
    "                vo_timestamps[0] = timestamp\n",
    "                continue\n",
    "\n",
    "            vo_timestamps.append(timestamp)\n",
    "\n",
    "            xyzrpy = [float(v) for v in row[2:8]]\n",
    "            rel_pose = build_se3_transform(xyzrpy)\n",
    "            abs_pose = abs_poses[-1] * rel_pose\n",
    "            abs_poses.append(abs_pose)\n",
    "\n",
    "            if timestamp >= upper_timestamp:\n",
    "                break\n",
    "\n",
    "    return interpolate_poses(vo_timestamps, abs_poses, pose_timestamps, origin_timestamp)\n",
    "\n",
    "\n",
    "def interpolate_ins_poses(ins_path, pose_timestamps, origin_timestamp):\n",
    "    \"\"\"Interpolate poses from INS.\n",
    "\n",
    "    Args:\n",
    "        ins_path (str): path to file containing poses from INS.\n",
    "        pose_timestamps (list[int]): UNIX timestamps at which interpolated poses are required.\n",
    "        origin_timestamp (int): UNIX timestamp of origin frame. Poses will be reported relative to this frame.\n",
    "\n",
    "    Returns:\n",
    "        list[numpy.matrixlib.defmatrix.matrix]: SE3 matrix representing interpolated pose for each requested timestamp.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(ins_path) as ins_file:\n",
    "        ins_reader = csv.reader(ins_file)\n",
    "        headers = next(ins_file)\n",
    "\n",
    "        ins_timestamps = [0]\n",
    "        abs_poses = [ml.identity(4)]\n",
    "\n",
    "        upper_timestamp = max(max(pose_timestamps), origin_timestamp)\n",
    "\n",
    "        for row in ins_reader:\n",
    "            timestamp = int(row[0])\n",
    "            ins_timestamps.append(timestamp)\n",
    "\n",
    "            xyzrpy = [float(v) for v in row[2:8]]\n",
    "            abs_pose = build_se3_transform(xyzrpy)\n",
    "            abs_poses.append(abs_pose)\n",
    "\n",
    "            if timestamp >= upper_timestamp:\n",
    "                break\n",
    "\n",
    "    ins_timestamps = ins_timestamps[1:]\n",
    "    abs_poses = abs_poses[1:]\n",
    "\n",
    "    return interpolate_poses(ins_timestamps, abs_poses, pose_timestamps, origin_timestamp)\n",
    "\n",
    "\n",
    "def interpolate_poses(pose_timestamps, abs_poses, requested_timestamps, origin_timestamp):\n",
    "    \"\"\"Interpolate between absolute poses.\n",
    "\n",
    "    Args:\n",
    "        pose_timestamps (list[int]): Timestamps of supplied poses. Must be in ascending order.\n",
    "        abs_poses (list[numpy.matrixlib.defmatrix.matrix]): SE3 matrices representing poses at the timestamps specified.\n",
    "        requested_timestamps (list[int]): Timestamps for which interpolated timestamps are required.\n",
    "        origin_timestamp (int): UNIX timestamp of origin frame. Poses will be reported relative to this frame.\n",
    "\n",
    "    Returns:\n",
    "        list[numpy.matrixlib.defmatrix.matrix]: SE3 matrix representing interpolated pose for each requested timestamp.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if pose_timestamps and abs_poses are not the same length\n",
    "        ValueError: if pose_timestamps is not in ascending order\n",
    "\n",
    "    \"\"\"\n",
    "    requested_timestamps.insert(0, origin_timestamp)\n",
    "    requested_timestamps = np.array(requested_timestamps)\n",
    "    pose_timestamps = np.array(pose_timestamps)\n",
    "\n",
    "    if len(pose_timestamps) != len(abs_poses):\n",
    "        raise ValueError('Must supply same number of timestamps as poses')\n",
    "\n",
    "    abs_quaternions = np.zeros((4, len(abs_poses)))\n",
    "    abs_positions = np.zeros((3, len(abs_poses)))\n",
    "    for i, pose in enumerate(abs_poses):\n",
    "        if i > 0 and pose_timestamps[i-1] >= pose_timestamps[i]:\n",
    "            raise ValueError('Pose timestamps must be in ascending order')\n",
    "\n",
    "        abs_quaternions[:, i] = so3_to_quaternion(pose[0:3, 0:3])\n",
    "        abs_positions[:, i] = np.ravel(pose[0:3, 3])\n",
    "\n",
    "    upper_indices = [bisect.bisect(pose_timestamps, pt) for pt in requested_timestamps]\n",
    "    lower_indices = [u - 1 for u in upper_indices]\n",
    "\n",
    "    if max(upper_indices) >= len(pose_timestamps):\n",
    "        upper_indices = [min(i, len(pose_timestamps) - 1) for i in upper_indices]\n",
    "\n",
    "    fractions = (requested_timestamps - pose_timestamps[lower_indices]) / \\\n",
    "                (pose_timestamps[upper_indices] - pose_timestamps[lower_indices])\n",
    "\n",
    "    quaternions_lower = abs_quaternions[:, lower_indices]\n",
    "    quaternions_upper = abs_quaternions[:, upper_indices]\n",
    "\n",
    "    d_array = (quaternions_lower * quaternions_upper).sum(0)\n",
    "\n",
    "    linear_interp_indices = np.nonzero(d_array >= 1)\n",
    "    sin_interp_indices = np.nonzero(d_array < 1)\n",
    "\n",
    "    scale0_array = np.zeros(d_array.shape)\n",
    "    scale1_array = np.zeros(d_array.shape)\n",
    "\n",
    "    scale0_array[linear_interp_indices] = 1 - fractions[linear_interp_indices]\n",
    "    scale1_array[linear_interp_indices] = fractions[linear_interp_indices]\n",
    "\n",
    "    theta_array = np.arccos(np.abs(d_array[sin_interp_indices]))\n",
    "\n",
    "    scale0_array[sin_interp_indices] = \\\n",
    "        np.sin((1 - fractions[sin_interp_indices]) * theta_array) / np.sin(theta_array)\n",
    "    scale1_array[sin_interp_indices] = \\\n",
    "        np.sin(fractions[sin_interp_indices] * theta_array) / np.sin(theta_array)\n",
    "\n",
    "    negative_d_indices = np.nonzero(d_array < 0)\n",
    "    scale1_array[negative_d_indices] = -scale1_array[negative_d_indices]\n",
    "\n",
    "    quaternions_interp = np.tile(scale0_array, (4, 1)) * quaternions_lower \\\n",
    "                         + np.tile(scale1_array, (4, 1)) * quaternions_upper\n",
    "\n",
    "    positions_lower = abs_positions[:, lower_indices]\n",
    "    positions_upper = abs_positions[:, upper_indices]\n",
    "\n",
    "    positions_interp = np.multiply(np.tile((1 - fractions), (3, 1)), positions_lower) \\\n",
    "                       + np.multiply(np.tile(fractions, (3, 1)), positions_upper)\n",
    "\n",
    "    poses_mat = ml.zeros((4, 4 * len(requested_timestamps)))\n",
    "\n",
    "    poses_mat[0, 0::4] = 1 - 2 * np.square(quaternions_interp[2, :]) - \\\n",
    "                         2 * np.square(quaternions_interp[3, :])\n",
    "    poses_mat[0, 1::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[2, :]) - \\\n",
    "                         2 * np.multiply(quaternions_interp[3, :], quaternions_interp[0, :])\n",
    "    poses_mat[0, 2::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[3, :]) + \\\n",
    "                         2 * np.multiply(quaternions_interp[2, :], quaternions_interp[0, :])\n",
    "\n",
    "    poses_mat[1, 0::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[2, :]) \\\n",
    "                         + 2 * np.multiply(quaternions_interp[3, :], quaternions_interp[0, :])\n",
    "    poses_mat[1, 1::4] = 1 - 2 * np.square(quaternions_interp[1, :]) \\\n",
    "                         - 2 * np.square(quaternions_interp[3, :])\n",
    "    poses_mat[1, 2::4] = 2 * np.multiply(quaternions_interp[2, :], quaternions_interp[3, :]) - \\\n",
    "                         2 * np.multiply(quaternions_interp[1, :], quaternions_interp[0, :])\n",
    "\n",
    "    poses_mat[2, 0::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[3, :]) - \\\n",
    "                         2 * np.multiply(quaternions_interp[2, :], quaternions_interp[0, :])\n",
    "    poses_mat[2, 1::4] = 2 * np.multiply(quaternions_interp[2, :], quaternions_interp[3, :]) + \\\n",
    "                         2 * np.multiply(quaternions_interp[1, :], quaternions_interp[0, :])\n",
    "    poses_mat[2, 2::4] = 1 - 2 * np.square(quaternions_interp[1, :]) - \\\n",
    "                         2 * np.square(quaternions_interp[2, :])\n",
    "\n",
    "    poses_mat[0:3, 3::4] = positions_interp\n",
    "    poses_mat[3, 3::4] = 1\n",
    "\n",
    "    poses_mat = np.linalg.solve(poses_mat[0:4, 0:4], poses_mat)\n",
    "\n",
    "    poses_out = [0] * (len(requested_timestamps) - 1)\n",
    "    for i in range(1, len(requested_timestamps)):\n",
    "        poses_out[i - 1] = poses_mat[0:4, i * 4:(i + 1) * 4]\n",
    "\n",
    "    return poses_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Conversions and Trajectory Plot Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import interpolate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load some variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderPath = \"/workspace/dataset2/current/data/oxford/\"\n",
    "# dataId = \"2014-12-09-13-21-02/\"\n",
    "dataId = \"2014-12-10-18-10-50/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert relative poses to global and then convert it into xyzrpy components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getInterpVO(voFile1,voData1,dataLim=6000):\n",
    "    # Get global SE3 poses\n",
    "    interpPoses = interpolate_vo_poses(voFile1,voData1[:dataLim,0].tolist(),voData1[0,0])\n",
    "    print(len(interpPoses),interpPoses[0].shape)\n",
    "\n",
    "    # Convert SE3 to xyzrpy\n",
    "    compPoses = []\n",
    "    for i in range(len(interpPoses)):\n",
    "        compPoses.append(se3_to_components(interpPoses[i]))\n",
    "    print(len(compPoses),compPoses[0].shape)\n",
    "    return np.array(compPoses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load vo\n",
    "voFile = folderPath+dataId+\"vo/vo.csv\"\n",
    "voData = np.loadtxt(voFile,delimiter=\",\",skiprows=1)\n",
    "print(\"VO Data Shape - \",voData.shape)\n",
    "\n",
    "compPosesArr = getInterpVO(voFile,voData,voData.shape[0])\n",
    "# Plot the gt vo\n",
    "print(compPosesArr.shape)\n",
    "plt.plot(compPosesArr[:,0],compPosesArr[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the calculated vo\n",
    "vo_calc = np.loadtxt(folderPath+dataId+\"1-poses_xyz.txt\")\n",
    "print(vo_calc.shape)\n",
    "plt.plot(vo_calc[:,2],vo_calc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS/INS Ground Truth for trajectories\n",
    "#### Interpolation method to align vo and ins data, and obtain ins coordinates for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getImageCords(insData,voData):\n",
    "    # interpolate latitude and longitude with respect to the timestamp index of these values\n",
    "    insDataPart = insData[:,[0,2,3]].astype(float)\n",
    "    latFunc = interpolate.interp1d(insDataPart[:,0],insDataPart[:,1])\n",
    "    longFunc = interpolate.interp1d(insDataPart[:,0],insDataPart[:,2])\n",
    "\n",
    "    # if VO data starts before GPS, we will have to skip it\n",
    "    numSkipVO = np.min(np.argwhere((voData[:,1] - insDataPart[0,0]) > 0))\n",
    "    print('Skipped',numSkipVO,\" VO values to align VO with GPS data\")\n",
    "    # Get lat and long for given timestamps in vo\n",
    "    lats = latFunc(voData[numSkipVO:,1])\n",
    "    longs = longFunc(voData[numSkipVO:,1])\n",
    "\n",
    "    # Plot the cords\n",
    "    plt.plot(longs,lats)\n",
    "    plt.title(\"Image Co-ordinates\")\n",
    "    plt.show()\n",
    "\n",
    "    imageCords = np.vstack((np.arange(longs.shape[0])+numSkipVO,lats,longs)).transpose()\n",
    "\n",
    "    return imageCords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load GPS/INS data\n",
    "insFile = folderPath+dataId+\"gps/ins.csv\"\n",
    "insData = np.loadtxt(insFile,skiprows=1,\n",
    "                    delimiter=',',dtype='str')\n",
    "print(insData.shape)\n",
    "plt.plot(insData[:,3],insData[:,2])\n",
    "plt.title(\"INS Ground Truth Data\")\n",
    "plt.show()\n",
    "\n",
    "imageCords = getImageCords(insData,voData)\n",
    "\n",
    "# Save the cords\n",
    "# np.savetxt(folderPath+dataId+\"imageCords.txt\",imageCords,fmt=['%d','%f','%f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed-Normalized / Constant-Distance Timestamps \n",
    "Following code is useful for sampling images at constant distance if their corresponding odometry/gps/ins is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getUsefulInds(deltaR_n_norm,unit=1):\n",
    "    # Store only the indices that are given units apart\n",
    "    usefulInds = []\n",
    "    # Keep a record of usefulInds wrt each raw index\n",
    "    usefulIndsCounter = []\n",
    "    cumSum = 0\n",
    "    for i in range(len(deltaR_n_norm)):\n",
    "        cumSum += deltaR_n_norm[i]\n",
    "        while cumSum > unit:\n",
    "            usefulInds.append(i)\n",
    "            cumSum -= unit\n",
    "        usefulIndsCounter.append(len(usefulInds))\n",
    "    return np.array(usefulInds), np.array(usefulIndsCounter)\n",
    "       \n",
    "    \n",
    "# Odomdata asssumed to have 3 cols - timestamp, x, y  \n",
    "# newTS assumed to have 1 col - timestamp\n",
    "def getOdomForTS(odomData,newTS):\n",
    "    xFunc = interpolate.interp1d(odomData[:,0],odomData[:,1])\n",
    "    yFunc = interpolate.interp1d(odomData[:,0],odomData[:,2])\n",
    "    \n",
    "    # if newTS data starts before odomTS, we will have to skip it\n",
    "    numSkipTS = np.min(np.argwhere((newTS - odomData[0,0]) > 0))\n",
    "    lastTSIdx = newTS.shape[0]\n",
    "    if newTS[-1] - odomData[-1,0] > 0:\n",
    "        lastTSIdx = np.min(np.argwhere((newTS-odomData[-1,0])>0))\n",
    "    print('Skipped',numSkipTS,\" values to align newTS with odomTS\")\n",
    "    # Get x and y for new timestamps\n",
    "    xNew = xFunc(newTS[numSkipTS:lastTSIdx])\n",
    "    yNew = yFunc(newTS[numSkipTS:lastTSIdx])\n",
    "    \n",
    "    # Plot the cords\n",
    "    plt.plot(yNew,xNew)\n",
    "    plt.title(\"Image Co-ordinates\")\n",
    "    plt.show()\n",
    "    \n",
    "    newTsCords = np.vstack((np.arange(xNew.shape[0])+numSkipTS,xNew,yNew)).transpose()\n",
    "\n",
    "    return newTsCords\n",
    "\n",
    "def sampleTSConstantDistance(imgCords1,factor=2):   \n",
    "    # Calc displacement\n",
    "    disp1 = np.linalg.norm(imgCords1[1:,1:] - imgCords1[:-1,1:],axis=1)\n",
    "    # append a disp value of zero at the beginning\n",
    "    disp1 = np.insert(disp1,0,0,)\n",
    "    print(\"Total image frames - \",disp1.shape)\n",
    "\n",
    "    # Calc avg distance travelled per image\n",
    "    avgDispPerImg1 = np.mean(disp1)\n",
    "    print(\"Avg Displacement per Image \", avgDispPerImg1)\n",
    "\n",
    "    # Get speed normalized / constant distance indices\n",
    "    usefulInds1, usefulIndsCounter1 = getUsefulInds(disp1,avgDispPerImg1*factor)\n",
    "    assert(len(usefulIndsCounter1)==len(disp1))\n",
    "    print(\"Constant-Distance Sampled Image frames - \",usefulInds1.shape)\n",
    "\n",
    "    # Plot the new co-ordinates separated by constant distance\n",
    "    plt.plot(imgCords1[usefulInds1,2],imgCords1[usefulInds1,1])\n",
    "    plt.title(\"Image Co-ordinates separated by constant distance\\n\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the speed\n",
    "    plt.plot(usefulIndsCounter1)\n",
    "    plt.title(\"Speed Profile\")\n",
    "    plt.show()\n",
    "    \n",
    "    return usefulInds1, usefulIndsCounter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following code calls functions above and requires prior loading of only ins/gps/odom data  and folderPath+dataID for input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor = \"mono_rear\"\n",
    "newTimeStamps = np.loadtxt(folderPath+dataId+sensor+\".timestamps\")[:,0]\n",
    "\n",
    "# Obtain the co-ordinates for new sensor\n",
    "imgCords = getOdomForTS(insData[:,[0,2,3]].astype(float),newTimeStamps)\n",
    "\n",
    "# Obtain the sampled indices\n",
    "sampledInds, sampledIndsIndex = sampleTSConstantDistance(imgCords,2)\n",
    "\n",
    "# print(\"Writing to path - \", folderPath+dataId)\n",
    "# np.savetxt(folderPath+dataId+sensor+\"_sampled_indices.txt\",sampledInds,fmt='%d')\n",
    "# np.savetxt(folderPath+dataId+sensor+\"_sampled_indices_index.txt\",sampledIndsIndex,fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ---- TO DO ---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Recognition Ground Truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageCords1 = np.loadtxt(folderPath+dataId+\"imageCords.txt\")\n",
    "imageCords2 = np.loadtxt(folderPath+dataId2+\"imageCords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if 2 is query, then matching index (of ref) for its each image is stored\n",
    "gtPR21 = []\n",
    "searchRegion = 2000\n",
    "diffVecs = []\n",
    "for i in range(imageCords2.shape[0]):\n",
    "    cord2 = imageCords2[i,1:]\n",
    "    searchStart = 0#min(max(0,i-searchRegion),imageCords1.shape[0]-searchRegion)\n",
    "    searchEnd = imageCords1.shape[0]#min(imageCords1.shape[0],i+searchRegion)\n",
    "    diffVec = (np.sum(abs(np.subtract(imageCords1[searchStart:searchEnd,1:],cord2)),axis=1))\n",
    "    matchIdx = np.argmin(diffVec)\n",
    "    diffVecs.append(diffVec)\n",
    "    gtPR21.append(searchStart+matchIdx)\n",
    "#     for j in range(imageCords1.shape[0]):\n",
    "#         cord1 = imageCords1[j,1:]\n",
    "        \n",
    "#         if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(gtPR21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.array(diffVecs))\n",
    "# print(len(diffVecs[2220]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
